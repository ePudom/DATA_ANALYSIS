{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb100b90-fc0a-4e4a-a399-f649eee0e477",
   "metadata": {},
   "source": [
    "## **Job Scrapper - INDEED**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b67890-5038-4341-bc37-f0e6efed187b",
   "metadata": {},
   "source": [
    "Create a general purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8af4e85e-241f-46f8-97b3-17f079fa15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46ec0ed2-e254-405c-bb9a-b0c35f621e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"f3a2132b-8986-4975-b0d8-47d1c186e0dc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47110071-10ed-48a5-8e72-8bb81cb3b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://ng.indeed.com'\n",
    "# LINKEDIN_BASE_URL = 'https://ng.linkedin.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c4838d3-8ab0-4fc9-b1c6-cff5f37ad962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(platform, job_title, location):\n",
    "    \"\"\"Generate URL based on the job title and location\"\"\"\n",
    "\n",
    "    template = BASE_URL + '/jobs?q={}&l={}'\n",
    "    \n",
    "    url = template.format(job_title, location)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bbe92e0-de2f-407e-ac82-5f1e76df615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scrapeops_url(url):\n",
    "    payload = {'api_key': API_KEY, 'url': url}\n",
    "    proxy_url = 'https://proxy.scrapeops.io/v1/?' + urllib.parse.urlencode(payload)\n",
    "    return proxy_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://proxy.scrapeops.io/v1/?api_key=f3a2132b-8986-4975-b0d8-47d1c186e0dc&url=https%3A%2F%2Fng.indeed.com%2Fjobs%3Fq%3Ddata+analyst%26l%3Dlagos'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = get_scrapeops_url(get_url('INDEED', 'data analyst', 'lagos'))\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99e31a22-14ef-46bb-9ccd-b7c3904da1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa62a83-de54-4c77-9ac0-13bbf601e7a2",
   "metadata": {},
   "source": [
    "### Extract raw html from Indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1999bab-865e-4ab3-849a-9e803680b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23eea6c4-0759-4737-ae24-1bc619774c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = soup.find_all(class_ = 'job_seen_beacon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f81c806-480c-4370-9061-797e8b0e133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b16a45-4a29-4a43-be54-a699de0a8b0f",
   "metadata": {},
   "source": [
    "### Prototype the extraction of a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db7ed5ca-027f-4f4e-b7f3-a4faafbbbbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"job_seen_beacon\"><table cellpadding=\"0\" cellspacing=\"0\" class=\"jobCard_mainContent big6_visualChanges\" role=\"presentation\"><tbody><tr><td class=\"resultContent\"><style data-emotion=\"css 1xpvg2o\">.css-1xpvg2o{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;margin:0;min-width:0;overflow:hidden;text-overflow:ellipsis;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;padding-right:2.6rem;}html[dir=rtl] .css-1xpvg2o{padding-right:0;padding-left:2.6rem;}</style><div class=\"css-1xpvg2o e37uo190\"><style data-emotion=\"css 1u6tfqq\">.css-1u6tfqq{box-sizing:border-box;margin:0;min-width:0;display:-webkit-box;-webkit-box-orient:vertical;font-size:1.125rem;line-height:1.5rem;margin:0;color:#2d2d2d;letter-spacing:-0.06px;overflow:hidden;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;font-weight:600;-webkit-line-clamp:2;}</style><h2 class=\"jobTitle css-1u6tfqq eu4oa1w0\" tabindex=\"-1\"><a aria-label=\"full details of Operations Data Analyst (Cement)\" class=\"jcs-JobTitle css-jspxzf eu4oa1w0\" data-hide-spinner=\"true\" data-hiring-event=\"false\" data-jk=\"8a9f0ba6281cc701\" data-mobtk=\"1hgplkhd32h5c000\" href=\"/rc/clk?jk=8a9f0ba6281cc701&amp;fccid=8350aecd95d957af&amp;vjs=3\" id=\"job_8a9f0ba6281cc701\" role=\"button\"><span id=\"jobTitle-8a9f0ba6281cc701\" title=\"Operations Data Analyst (Cement)\">Operations Data Analyst (Cement)</span></a></h2></div><div class=\"company_location css-12lvszk e37uo190\"><div data-testid=\"timing-attribute\" elementtiming=\"significant-render\"><span class=\"css-1x7z1ps eu4oa1w0\" data-testid=\"company-name\">Dangote Industries Limited</span><div class=\"css-t4u72d eu4oa1w0\" data-testid=\"text-location\">Lagos</div></div></div><div class=\"heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly\"><div class=\"metadata\"><style data-emotion=\"css 1ihavw2\">.css-1ihavw2{box-sizing:border-box;margin:0;min-width:0;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;background-color:#f3f2f1;border-radius:0.25rem;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:0.875rem;font-weight:700;line-height:1.3125rem;color:#595959;padding:0.1875rem 0.5rem;margin-right:0.25rem;margin-bottom:0.25rem;}.css-1ihavw2 svg{width:1rem;max-height:1.25rem;}[dir=\"ltr\"] .css-1ihavw2 svg:first-child{margin:0 0 0 0.25rem;}[dir=\"rtl\"] .css-1ihavw2 svg:first-child{margin:0 0 0 0.25rem;}.css-1ihavw2 svg.jobCardAQSignalIcon-check{margin:0 0 0 0.25rem;}</style><div class=\"css-1ihavw2 eu4oa1w0\" data-testid=\"attribute_snippet_testid\">Full-time</div></div></div><div class=\"heading6 error-text tapItem-gutter\"></div></td></tr></tbody></table><table class=\"css-1u8dvic eu4oa1w0\" role=\"presentation\"><tbody><style data-emotion=\"css mvf9iq\">.css-mvf9iq{box-sizing:border-box;margin:0;min-width:0;display:block;padding-right:0;padding-left:1rem;padding-bottom:0.25rem;}[dir=\"rtl\"] .css-mvf9iq{padding-right:1rem;padding-left:0;}</style><tr class=\"css-mvf9iq eu4oa1w0\"></tr><tr class=\"underShelfFooter\"><td><div class=\"heading6 tapItem-gutter result-footer\"><div class=\"job-snippet\"><ul style=\"list-style-type:circle;margin-top: 0px;margin-bottom: 0px;padding-left:20px;\">\n",
       "<li>Collect, analyze, and interpret operational <b>data</b> to identify trends and performance indicators Develop and maintain reporting systems to track key metrics and…</li>\n",
       "</ul></div><span class=\"date\"><span class=\"visually-hidden\">Posted</span>Posted 18 days ago</span><span class=\"result-link-bar-separator\">·</span><button aria-expanded=\"false\" class=\"sl resultLink more_links_button\" type=\"button\">More...</button></div><div class=\"tab-container\"><div class=\"more-links-container result-tab\"><div class=\"more_links\"><button aria-label=\"Close\" class=\"close-button\" title=\"Close\" type=\"button\"></button><ul><li><span class=\"mat\">View all <style data-emotion=\"css 1f8zkg3\">.css-1f8zkg3{border-radius:0;color:#2557a7;font-family:\"Noto Sans\",\"Helvetica Neue\",\"Helvetica\",\"Arial\",\"Liberation Sans\",\"Roboto\",\"Noto\",sans-serif;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:border-color 200ms cubic-bezier(0.645, 0.045, 0.355, 1),background-color 200ms cubic-bezier(0.645, 0.045, 0.355, 1),opacity 200ms cubic-bezier(0.645, 0.045, 0.355, 1),border-bottom-color 200ms cubic-bezier(0.645, 0.045, 0.355, 1),border-bottom-style 200ms cubic-bezier(0.645, 0.045, 0.355, 1),border-bottom-width 200ms cubic-bezier(0.645, 0.045, 0.355, 1),border-radius 200ms cubic-bezier(0.645, 0.045, 0.355, 1),box-shadow 200ms cubic-bezier(0.645, 0.045, 0.355, 1),color 200ms cubic-bezier(0.645, 0.045, 0.355, 1);transition:border-color 200ms cubic-bezier(0.645, 0.045, 0.355, 1),background-color 200ms cubic-bezier(0.645, 0.045, 0.355, 1),opacity 200ms cubic-bezier(0.645, 0.045, 0.355, 1),border-bottom-color 200ms cubic-bezier(0.645, 0.045, 0.355, 1),border-bottom-style 200ms cubic-bezier(0.645, 0.045, 0.355, 1),border-bottom-width 200ms cubic-bezier(0.645, 0.045, 0.355, 1),border-radius 200ms cubic-bezier(0.645, 0.045, 0.355, 1),box-shadow 200ms cubic-bezier(0.645, 0.045, 0.355, 1),color 200ms cubic-bezier(0.645, 0.045, 0.355, 1);border-bottom:1px solid;cursor:pointer;}.css-1f8zkg3:hover{color:#164081;}.css-1f8zkg3:active{color:#0d2d5e;}.css-1f8zkg3:focus{outline:none;border-bottom:1px solid;border-bottom-color:transparent;border-radius:4px;box-shadow:0 0 0 1px;}.css-1f8zkg3:focus:not([data-focus-visible-added]){box-shadow:none;border-bottom:1px solid;border-radius:0;}.css-1f8zkg3:visited{color:#2557a7;}.css-1f8zkg3:hover,.css-1f8zkg3:active{color:#164081;}@media (prefers-reduced-motion: reduce){.css-1f8zkg3{-webkit-transition:none;transition:none;}}.css-1f8zkg3:focus:active:not([data-focus-visible-added]){box-shadow:none;border-bottom:1px solid;border-radius:0;}</style><a class=\"css-1f8zkg3 e19afand0\" href=\"/q-dangote-industries-limited-jobs.html\">Dangote Industries Limited jobs</a> - <a class=\"css-1f8zkg3 e19afand0\" href=\"/l-lagos-jobs.html\">Lagos jobs</a> - <a class=\"css-1f8zkg3 e19afand0\" href=\"/q-data-analyst-l-lagos-jobs.html\">Data Analyst jobs in Lagos</a></span></li><li><span class=\"mat\">Salary Search: <a class=\"css-1f8zkg3 e19afand0\" href=\"/career/salaries/Data%20Analyst/Lagos?campaignid=serp-more&amp;fromjk=8a9f0ba6281cc701&amp;from=serp-more\">Operations Data Analyst (Cement) salaries</a></span></li><li><span class=\"mat\">See popular <a class=\"css-1f8zkg3 e19afand0\" href=\"/cmp/Dangote-Industries-Ltd/faq\">questions &amp; answers about Dangote Industries Limited</a></span></li></ul></div></div></div></td></tr></tbody></table><div aria-live=\"polite\"></div></div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card = cards[0]\n",
    "card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table cellpadding=\"0\" cellspacing=\"0\" class=\"jobCard_mainContent big6_visualChanges\" role=\"presentation\"><tbody><tr><td class=\"resultContent\"><style data-emotion=\"css 1xpvg2o\">.css-1xpvg2o{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;margin:0;min-width:0;overflow:hidden;text-overflow:ellipsis;-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;padding-right:2.6rem;}html[dir=rtl] .css-1xpvg2o{padding-right:0;padding-left:2.6rem;}</style><div class=\"css-1xpvg2o e37uo190\"><style data-emotion=\"css 1u6tfqq\">.css-1u6tfqq{box-sizing:border-box;margin:0;min-width:0;display:-webkit-box;-webkit-box-orient:vertical;font-size:1.125rem;line-height:1.5rem;margin:0;color:#2d2d2d;letter-spacing:-0.06px;overflow:hidden;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;font-weight:600;-webkit-line-clamp:2;}</style><h2 class=\"jobTitle css-1u6tfqq eu4oa1w0\" tabindex=\"-1\"><a aria-label=\"full details of Operations Data Analyst (Cement)\" class=\"jcs-JobTitle css-jspxzf eu4oa1w0\" data-hide-spinner=\"true\" data-hiring-event=\"false\" data-jk=\"8a9f0ba6281cc701\" data-mobtk=\"1hgplkhd32h5c000\" href=\"/rc/clk?jk=8a9f0ba6281cc701&amp;fccid=8350aecd95d957af&amp;vjs=3\" id=\"job_8a9f0ba6281cc701\" role=\"button\"><span id=\"jobTitle-8a9f0ba6281cc701\" title=\"Operations Data Analyst (Cement)\">Operations Data Analyst (Cement)</span></a></h2></div><div class=\"company_location css-12lvszk e37uo190\"><div data-testid=\"timing-attribute\" elementtiming=\"significant-render\"><span class=\"css-1x7z1ps eu4oa1w0\" data-testid=\"company-name\">Dangote Industries Limited</span><div class=\"css-t4u72d eu4oa1w0\" data-testid=\"text-location\">Lagos</div></div></div><div class=\"heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly\"><div class=\"metadata\"><style data-emotion=\"css 1ihavw2\">.css-1ihavw2{box-sizing:border-box;margin:0;min-width:0;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;background-color:#f3f2f1;border-radius:0.25rem;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:0.875rem;font-weight:700;line-height:1.3125rem;color:#595959;padding:0.1875rem 0.5rem;margin-right:0.25rem;margin-bottom:0.25rem;}.css-1ihavw2 svg{width:1rem;max-height:1.25rem;}[dir=\"ltr\"] .css-1ihavw2 svg:first-child{margin:0 0 0 0.25rem;}[dir=\"rtl\"] .css-1ihavw2 svg:first-child{margin:0 0 0 0.25rem;}.css-1ihavw2 svg.jobCardAQSignalIcon-check{margin:0 0 0 0.25rem;}</style><div class=\"css-1ihavw2 eu4oa1w0\" data-testid=\"attribute_snippet_testid\">Full-time</div></div></div><div class=\"heading6 error-text tapItem-gutter\"></div></td></tr></tbody></table>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_content = card.find('table', 'jobCard_mainContent')\n",
    "header_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "221d9842-485a-4549-a279-54fdede0a501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a aria-label=\"full details of Operations Data Analyst (Cement)\" class=\"jcs-JobTitle css-jspxzf eu4oa1w0\" data-hide-spinner=\"true\" data-hiring-event=\"false\" data-jk=\"8a9f0ba6281cc701\" data-mobtk=\"1hgplkhd32h5c000\" href=\"/rc/clk?jk=8a9f0ba6281cc701&amp;fccid=8350aecd95d957af&amp;vjs=3\" id=\"job_8a9f0ba6281cc701\" role=\"button\"><span id=\"jobTitle-8a9f0ba6281cc701\" title=\"Operations Data Analyst (Cement)\">Operations Data Analyst (Cement)</span></a>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atag = header_content.h2.a\n",
    "atag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a5242fd-3a71-405b-8d47-baaef5fd4ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operations Data Analyst (Cement)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    job_title = atag.span.text\n",
    "except AttributeError:\n",
    "    job_title = atag.text\n",
    "\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f32bddb-8b46-4aab-b3ea-c15409df695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ng.indeed.com/rc/clk?jk=8a9f0ba6281cc701&fccid=8350aecd95d957af&vjs=3'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_url = BASE_URL + atag.get('href')\n",
    "job_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54135dc9-4945-497b-9d19-3fc55b1d79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_ = header_content.find('div', 'company_location').span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9881f754-c909-420d-92b6-00ca2d9b8fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dangote Industries Limited'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company = company_.text\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3022b090-3860-4bf5-a766-a0de393234dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lagos'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_location = company_.next_sibling.text\n",
    "company_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83f48f3e-9e05-4b10-b351-7fd647f532b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"metadata\"><style data-emotion=\"css 1ihavw2\">.css-1ihavw2{box-sizing:border-box;margin:0;min-width:0;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;background-color:#f3f2f1;border-radius:0.25rem;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:0.875rem;font-weight:700;line-height:1.3125rem;color:#595959;padding:0.1875rem 0.5rem;margin-right:0.25rem;margin-bottom:0.25rem;}.css-1ihavw2 svg{width:1rem;max-height:1.25rem;}[dir=\"ltr\"] .css-1ihavw2 svg:first-child{margin:0 0 0 0.25rem;}[dir=\"rtl\"] .css-1ihavw2 svg:first-child{margin:0 0 0 0.25rem;}.css-1ihavw2 svg.jobCardAQSignalIcon-check{margin:0 0 0 0.25rem;}</style><div class=\"css-1ihavw2 eu4oa1w0\" data-testid=\"attribute_snippet_testid\">Full-time</div></div>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = header_content.find('div', 'metadataContainer').find_all('div', 'metadata')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full-time'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = \"\"\n",
    "time_commitment = \"\"\n",
    "\n",
    "try:\n",
    "    if len(metadata) > 1:\n",
    "        salary = metadata[0].div.text\n",
    "        time_commitment = metadata[1].div.text\n",
    "    else:\n",
    "        time_commitment = metadata[0].div.text\n",
    "except IndexError:\n",
    "    salary = None\n",
    "    time_commitment = None\n",
    "    print('metadata is missing', metadata)\n",
    "\n",
    "salary\n",
    "time_commitment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "817fe86a-0727-471e-ab2d-a045fcde1eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"job-snippet\"><ul style=\"list-style-type:circle;margin-top: 0px;margin-bottom: 0px;padding-left:20px;\">\n",
       " <li>Collect, analyze, and interpret operational <b>data</b> to identify trends and performance indicators Develop and maintain reporting systems to track key metrics and…</li>\n",
       " </ul></div>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card.find_all('div', 'job-snippet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Collect, analyze, and interpret operational data to identify trends and performance indicators Develop and maintain reporting systems to track key metrics and…\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description_ = card.find('div', 'job-snippet').find_all('li')\n",
    "job_description = \"\"\n",
    "\n",
    "for description in job_description_:\n",
    "    job_description += description.text + \"\\n\"\n",
    "\n",
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"date\"><span class=\"visually-hidden\">Posted</span>Posted 18 days ago</span>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_date_ = card.find('span', 'date')\n",
    "post_date_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"visually-hidden\">Posted</span>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwanted = post_date_.find('span', 'visually-hidden')\n",
    "unwanted.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Posted 18 days ago'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_date = post_date_.text\n",
    "post_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize the extraction model with a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_indeed(card):\n",
    "    \"\"\"Extact job record from a single record\"\"\"\n",
    "    header_content = card.find('table', 'jobCard_mainContent')\n",
    "\n",
    "    atag = header_content.h2.a\n",
    "    try:\n",
    "        job_title = atag.span.text\n",
    "    except AttributeError:\n",
    "        job_title = atag.text\n",
    "\n",
    "    job_url = BASE_URL + atag.get('href')\n",
    "    \n",
    "    company_ = header_content.find('div', 'company_location').span\n",
    "    company = company_.text\n",
    "\n",
    "    company_location = company_.next_sibling.text\n",
    "\n",
    "    metadata = header_content.find('div', 'metadataContainer').find_all('div', 'metadata')\n",
    "    salary = \"\"\n",
    "    time_commitment = \"\"\n",
    "\n",
    "    try:\n",
    "        if len(metadata) > 1:\n",
    "            salary = metadata[0].div.text\n",
    "            time_commitment = metadata[1].div.text\n",
    "        else:\n",
    "            time_commitment = metadata[0].div.text\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        job_description_ = card.find('div', 'job-snippet').find_all('li')\n",
    "        job_description = \"\"\n",
    "\n",
    "        for description in job_description_:\n",
    "            job_description += description.text + \"\\n\"\n",
    "    except AttributeError:\n",
    "        job_description = \"\"\n",
    "\n",
    "    post_date_ = card.find('span', 'date')\n",
    "\n",
    "    try: \n",
    "        unwanted = post_date_.find('span', 'visually-hidden')\n",
    "        unwanted.extract()\n",
    "\n",
    "        post_date = post_date_.text\n",
    "\n",
    "    except AttributeError:\n",
    "        post_date = post_date_.text\n",
    "\n",
    "    today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    record = (job_title, job_url, company, company_location, salary, time_commitment, job_description, post_date, today)\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Operations Data Analyst (Cement)', 'https://ng.indeed.com/rc/clk?jk=8a9f0ba6281cc701&fccid=8350aecd95d957af&vjs=3', 'Dangote Industries Limited', 'Lagos', '', 'Full-time', 'Collect, analyze, and interpret operational data to identify trends and performance indicators Develop and maintain reporting systems to track key metrics and…\\n', 'Posted 18 days ago', '2023-12-04'), ('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=386c3d2a2fb3a730&fccid=7d2e760617fdc83c&vjs=3', 'Leaders Network', 'Lagos', '', 'Full-time', 'Data Mining: Experience with data mining and data extraction from various sources.\\nData Governance: Ensure data is handled in compliance with relevant data…\\n', 'Posted 30+ days ago', '2023-12-04'), ('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=2fd62fc0485298df&fccid=afbf69e9eb7dd6e6&vjs=3', 'Gomoney', 'Lagos', '', '', 'Develop and maintain databases, data systems and reorganize data in a readable format.\\nWork with the data scientist, engineers, and management to identify…\\n', 'Posted 19 days ago', '2023-12-04'), ('Analyst, Customer Experience', 'https://ng.indeed.com/rc/clk?jk=f2363b35bb820604&fccid=5249cd8e17163cb5&vjs=3', 'Standard Chartered', 'Lagos', '', 'Full-time +1', 'Ensuring timely data entry on updates of actions taken to resolve the complaint in CEMS.\\nEnsure adherence to the Group Retail Banking Complaints Handling…\\n', 'Posted 13 days ago', '2023-12-04'), ('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=ce7fccf017f51309&fccid=3e9359119b425c78&vjs=3', 'Jumia', 'Lagos', '', 'Full-time', 'Providing technical expertise in data storage structures, data mining, and data cleansing.\\nProvide quality assurance of imported data, working with quality…\\n', 'Posted 12 days ago', '2023-12-04'), ('Chemical Laboratory Analyst', 'https://ng.indeed.com/rc/clk?jk=ba1e300a36ab95ca&fccid=fd901a721c7cb0af&vjs=3', 'Jawura Environmental Services Limited', 'Lagos', '', 'Full-time', 'Proficiency in laboratory software and data analysis tools.\\nCollaborate with the project team to support data interpretation and reporting.\\n', 'Posted 30+ days ago', '2023-12-04'), ('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=48d56561de49cf5c&fccid=29476644f3200de9&vjs=3', 'Mopheth Group', 'Lagos', '', 'Full-time', 'Work closely with cross-functional teams, including accounting and finance, to understand data requirements and contribute to data-driven decision-making…\\n', 'Posted 11 days ago', '2023-12-04'), ('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=19483f049f2891e2&fccid=39e6ec82667463ad&vjs=3', 'IpNX Nigeria Limited', 'Lagos', '', 'Full-time', 'Design and develop data models and data schemas to support efficient data analysis and reporting processes.\\nParticipate in data governance initiatives, ensuring…\\n', 'Posted 4 days ago', '2023-12-04'), ('Data Analyst Instructor', 'https://ng.indeed.com/rc/clk?jk=d92c41b5b5149378&fccid=eb73d67514554c5a&vjs=3', 'Tech365', 'Lagos', '', 'Full-time', 'Previous experience in data analysis, teaching, or training roles is preferred.\\nStay Updated: Keep abreast of industry trends, tools, and technologies in data…\\n', 'Posted 3 days ago', '2023-12-04'), ('Growth Data Analyst', 'https://ng.indeed.com/rc/clk?jk=d149d41995eefe47&fccid=515a2c959c12a211&vjs=3', 'Moniepoint Inc', 'Lagos', '', 'Full-time', 'Work closely with product managers, business, development and data engineering teams to guide the marketing and growth team including Growth Product in problem…\\n', 'Posted 30+ days ago', '2023-12-04'), ('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=a9397844c8f1fb50&fccid=c1d86172f11e7762&vjs=3', 'RS Hunter Ltd', 'Yaba', '', 'Full-time', 'Technical expertise regarding data models, database design development, data mining and segmentation techniques.\\nProven working experience in data analysis.\\n', 'Posted 30+ days ago', '2023-12-04'), ('Strategy Analyst', 'https://ng.indeed.com/rc/clk?jk=f9fdf2b543205166&fccid=4e30fd31331e3f76&vjs=3', 'Hugo', 'Lagos', '', '', 'You have strong analytical skills, a passion for data, and a critical-thinking mindset.\\nWe specialize in AI operations and omnichannel customer support.\\n', 'Posted 30+ days ago', '2023-12-04'), ('Financial Data Analyst', 'https://ng.indeed.com/rc/clk?jk=5780c15b34651590&fccid=515a2c959c12a211&vjs=3', 'Moniepoint Inc', 'Lagos', '', 'Full-time', 'Work with business stakeholders to identify reporting and analytics requirements Design and develop data models, data pipelines, and ETL processes to support BI…\\n', 'Posted 23 days ago', '2023-12-04'), ('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=e77d0329723235d4&fccid=8384cf51278c2a2a&vjs=3', 'High Caliber Nigeria Limited', 'Lagos', '', 'Full-time', 'Developing and maintaining databases, and data systems, reorganizing data in a readable format.\\nUsing automated tools to extract data from primary and secondary…\\n', 'Posted 3 days ago', '2023-12-04'), ('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=8f32034d40001905&fccid=c2cdbe1e2346fbb1&vjs=3', 'HRBP Limited', 'Lagos', '', 'Full-time', 'This position is responsible for extracting data from multiple sources, manipulating and validating data, and conducting root cause analysis.\\n', 'Posted 20 days ago', '2023-12-04')]\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for card in cards:\n",
    "    record = extract_data_from_indeed(card)\n",
    "    records.append(record)\n",
    "\n",
    "print(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        url = BASE_URL + soup.find('a', {'aria-label' : 'Next Page'}).get('href')\n",
    "        url = get_scrapeops_url(url)\n",
    "    except AttributeError:\n",
    "        break\n",
    "\n",
    "    response = requests.get(url)\n",
    "    print(response)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    cards = soup.find_all('div', {'class' : 'job_seen_beacon'})\n",
    "\n",
    "    for card in cards:\n",
    "        record = extract_data_from_indeed(card)\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerieving job data from https://proxy.scrapeops.io/v1/?api_key=f3a2132b-8986-4975-b0d8-47d1c186e0dc&url=https%3A%2F%2Fng.indeed.com%2Fjobs%3Fq%3Ddata+analyst%26l%3Dlagos\n",
      "Retrieved record 0\n",
      "('Operations Data Analyst (Cement)', 'https://ng.indeed.com/rc/clk?jk=8a9f0ba6281cc701&fccid=8350aecd95d957af&vjs=3', 'Dangote Industries Limited', 'Lagos', '', '', 'Collect, analyze, and interpret operational data to identify trends and performance indicators Develop and maintain reporting systems to track key metrics and…\\n', 'Posted 18 days ago', '2023-12-04')\n",
      "Retrieved record 1\n",
      "('Data Analyst Instructor', 'https://ng.indeed.com/rc/clk?jk=d92c41b5b5149378&fccid=eb73d67514554c5a&vjs=3', 'Tech365', 'Lagos', '', '', 'Previous experience in data analysis, teaching, or training roles is preferred.\\nStay Updated: Keep abreast of industry trends, tools, and technologies in data…\\n', 'Posted 3 days ago', '2023-12-04')\n",
      "Retrieved record 2\n",
      "('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=386c3d2a2fb3a730&fccid=7d2e760617fdc83c&vjs=3', 'Leaders Network', 'Lagos', '', '', 'Data Mining: Experience with data mining and data extraction from various sources.\\nData Governance: Ensure data is handled in compliance with relevant data…\\n', 'Posted 30+ days ago', '2023-12-04')\n",
      "Retrieved record 3\n",
      "('Analyst, Customer Experience', 'https://ng.indeed.com/rc/clk?jk=f2363b35bb820604&fccid=5249cd8e17163cb5&vjs=3', 'Standard Chartered', 'Lagos', '', '', 'Ensuring timely data entry on updates of actions taken to resolve the complaint in CEMS.\\nEnsure adherence to the Group Retail Banking Complaints Handling…\\n', 'Posted 13 days ago', '2023-12-04')\n",
      "Retrieved record 4\n",
      "('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=2fd62fc0485298df&fccid=afbf69e9eb7dd6e6&vjs=3', 'Gomoney', 'Lagos', '', '', 'Develop and maintain databases, data systems and reorganize data in a readable format.\\nWork with the data scientist, engineers, and management to identify…\\n', 'Posted 19 days ago', '2023-12-04')\n",
      "Retrieved record 5\n",
      "('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=19483f049f2891e2&fccid=39e6ec82667463ad&vjs=3', 'IpNX Nigeria Limited', 'Lagos', '', '', 'Design and develop data models and data schemas to support efficient data analysis and reporting processes.\\nParticipate in data governance initiatives, ensuring…\\n', 'Posted 4 days ago', '2023-12-04')\n",
      "Retrieved record 6\n",
      "('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=ce7fccf017f51309&fccid=3e9359119b425c78&vjs=3', 'Jumia', 'Lagos', '', '', 'Providing technical expertise in data storage structures, data mining, and data cleansing.\\nProvide quality assurance of imported data, working with quality…\\n', 'Posted 12 days ago', '2023-12-04')\n",
      "Retrieved record 7\n",
      "('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=e77d0329723235d4&fccid=8384cf51278c2a2a&vjs=3', 'High Caliber Nigeria Limited', 'Lagos', '', '', 'Developing and maintaining databases, and data systems, reorganizing data in a readable format.\\nUsing automated tools to extract data from primary and secondary…\\n', 'Posted 3 days ago', '2023-12-04')\n",
      "Retrieved record 8\n",
      "('Strategy Analyst', 'https://ng.indeed.com/rc/clk?jk=f9fdf2b543205166&fccid=4e30fd31331e3f76&vjs=3', 'Hugo', 'Lagos', '', '', 'You have strong analytical skills, a passion for data, and a critical-thinking mindset.\\nWe specialize in AI operations and omnichannel customer support.\\n', 'Posted 30+ days ago', '2023-12-04')\n",
      "Retrieved record 9\n",
      "('Chemical Laboratory Analyst', 'https://ng.indeed.com/rc/clk?jk=ba1e300a36ab95ca&fccid=fd901a721c7cb0af&vjs=3', 'Jawura Environmental Services Limited', 'Lagos', '', '', 'Proficiency in laboratory software and data analysis tools.\\nCollaborate with the project team to support data interpretation and reporting.\\n', 'Posted 30+ days ago', '2023-12-04')\n",
      "Retrieved record 10\n",
      "('Financial Data Analyst', 'https://ng.indeed.com/rc/clk?jk=5780c15b34651590&fccid=515a2c959c12a211&vjs=3', 'Moniepoint Inc', 'Lagos', '', '', 'Work with business stakeholders to identify reporting and analytics requirements Design and develop data models, data pipelines, and ETL processes to support BI…\\n', 'Posted 23 days ago', '2023-12-04')\n",
      "Retrieved record 11\n",
      "('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=48d56561de49cf5c&fccid=29476644f3200de9&vjs=3', 'Mopheth Group', 'Lagos', '', '', 'Work closely with cross-functional teams, including accounting and finance, to understand data requirements and contribute to data-driven decision-making…\\n', 'Posted 11 days ago', '2023-12-04')\n",
      "Retrieved record 12\n",
      "('Sales Support analyst', 'https://ng.indeed.com/rc/clk?jk=7cd721a630b2c3c0&fccid=bfdac90a7574b77c&vjs=3', 'Nestle Operational Services Worldwide SA', 'Lagos', '', '', 'Minimum 2 years sales / data analytics background.\\nMinimum Relevant Work Experience: Minimum 2 years sales /data analytics background.\\n', 'Posted 3 days ago', '2023-12-04')\n",
      "Retrieved record 13\n",
      "('Data Analyst', 'https://ng.indeed.com/rc/clk?jk=8f32034d40001905&fccid=c2cdbe1e2346fbb1&vjs=3', 'HRBP Limited', 'Lagos', '', '', 'This position is responsible for extracting data from multiple sources, manipulating and validating data, and conducting root cause analysis.\\n', 'Posted 20 days ago', '2023-12-04')\n",
      "Retrieved record 14\n",
      "('Growth Data Analyst', 'https://ng.indeed.com/rc/clk?jk=d149d41995eefe47&fccid=515a2c959c12a211&vjs=3', 'Moniepoint Inc', 'Lagos', '', '', 'Work closely with product managers, business, development and data engineering teams to guide the marketing and growth team including Growth Product in problem…\\n', 'Posted 30+ days ago', '2023-12-04')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bisol\\OneDrive\\Documents\\DATA ANALYTICS\\Portfolio Projects\\Job Search\\indeed-scrapy.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/bisol/OneDrive/Documents/DATA%20ANALYTICS/Portfolio%20Projects/Job%20Search/indeed-scrapy.ipynb#X61sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m         writer\u001b[39m.\u001b[39mwriterow(fieldnames)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/bisol/OneDrive/Documents/DATA%20ANALYTICS/Portfolio%20Projects/Job%20Search/indeed-scrapy.ipynb#X61sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m         writer\u001b[39m.\u001b[39mwriterows(records)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/bisol/OneDrive/Documents/DATA%20ANALYTICS/Portfolio%20Projects/Job%20Search/indeed-scrapy.ipynb#X61sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m main(\u001b[39m'\u001b[39m\u001b[39mdata analyst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlagos\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\bisol\\OneDrive\\Documents\\DATA ANALYTICS\\Portfolio Projects\\Job Search\\indeed-scrapy.ipynb Cell 38\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bisol/OneDrive/Documents/DATA%20ANALYTICS/Portfolio%20Projects/Job%20Search/indeed-scrapy.ipynb#X61sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39m# extract job data \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bisol/OneDrive/Documents/DATA%20ANALYTICS/Portfolio%20Projects/Job%20Search/indeed-scrapy.ipynb#X61sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bisol/OneDrive/Documents/DATA%20ANALYTICS/Portfolio%20Projects/Job%20Search/indeed-scrapy.ipynb#X61sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bisol/OneDrive/Documents/DATA%20ANALYTICS/Portfolio%20Projects/Job%20Search/indeed-scrapy.ipynb#X61sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRerieving job data from\u001b[39m\u001b[39m\"\u001b[39m, url)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bisol/OneDrive/Documents/DATA%20ANALYTICS/Portfolio%20Projects/Job%20Search/indeed-scrapy.ipynb#X61sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     \u001b[39mif\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    714\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    716\u001b[0m     conn,\n\u001b[0;32m    717\u001b[0m     method,\n\u001b[0;32m    718\u001b[0m     url,\n\u001b[0;32m    719\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    720\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    721\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    722\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    723\u001b[0m )\n\u001b[0;32m    725\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    729\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\site-packages\\urllib3\\connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    462\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m             six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\site-packages\\urllib3\\connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 462\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    463\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    464\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         response\u001b[39m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1308\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1309\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1310\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1311\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1312\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\bisol\\anaconda3\\envs\\dev1\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "API_KEY = \"f3a2132b-8986-4975-b0d8-47d1c186e0dc\"\n",
    "\n",
    "BASE_URL = 'https://ng.indeed.com'\n",
    "\n",
    "def get_url(job_title, location):\n",
    "    \"\"\"Generate URL based on the job title and location\"\"\"\n",
    "    template = BASE_URL + '/jobs?q={}&l={}'\n",
    "    url = template.format(job_title, location)\n",
    "    return url\n",
    "\n",
    "def get_scrapeops_url(url):\n",
    "    payload = {'api_key': API_KEY, 'url': url}\n",
    "    proxy_url = 'https://proxy.scrapeops.io/v1/?' + urllib.parse.urlencode(payload)\n",
    "    return proxy_url\n",
    "\n",
    "\n",
    "def extract_data(card):\n",
    "    \"\"\"Extact job record from a single record\"\"\"\n",
    "\n",
    "    header_content = card.find('table', 'jobCard_mainContent')\n",
    "\n",
    "    atag = header_content.h2.a\n",
    "\n",
    "    try:\n",
    "        job_title = atag.span.text\n",
    "    except AttributeError:\n",
    "        job_title = atag.text\n",
    "\n",
    "    job_url = BASE_URL + atag.get('href')\n",
    "    \n",
    "    company_ = header_content.find('div', 'company_location').span\n",
    "    company = company_.text\n",
    "\n",
    "    company_location = company_.next_sibling.text\n",
    "\n",
    "    metadata = header_content.find('div', 'metadataContainer').find_all('div', 'metadata')\n",
    "    \n",
    "    try:\n",
    "        salary = \"\"\n",
    "        time_commitment = \"\"\n",
    "\n",
    "        if len(metadata) > 1:\n",
    "            salary = metadata[0].div.text\n",
    "            time_commitment = metadata[1].div.text\n",
    "        else:\n",
    "            time_commitment = metadata[0].div.text\n",
    "    except IndexError:\n",
    "        time_commitment = \"\"\n",
    "        salary = \"\"\n",
    "\n",
    "    try:\n",
    "        job_description_ = card.find('div', 'job-snippet').find_all('li')\n",
    "        job_description = \"\"\n",
    "\n",
    "        for description in job_description_:\n",
    "            job_description += description.text + \"\\n\"\n",
    "    except AttributeError:\n",
    "        job_description = \"\"\n",
    "\n",
    "    post_date_ = card.find('span', 'date')\n",
    "\n",
    "    try: \n",
    "        unwanted = post_date_.find('span', 'visually-hidden')\n",
    "        unwanted.extract()\n",
    "\n",
    "        post_date = post_date_.text\n",
    "    except AttributeError:\n",
    "        post_date = post_date_.text\n",
    "\n",
    "    today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    record = (job_title, job_url, company, company_location, salary, time_commitment, job_description, post_date, today)\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def main(position, location):\n",
    "    \"\"\"Main function\"\"\"\n",
    "\n",
    "    records = []\n",
    "    url = get_scrapeops_url(get_url(position, location))\n",
    "    count = 0\n",
    "\n",
    "    # extract job data \n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        print(\"Rerieving job data from\", url)\n",
    "\n",
    "        if(response.status_code != 200):\n",
    "            print(\"Error retrieving job data from \", url)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        cards = soup.find_all('div', {'class' : 'job_seen_beacon'})\n",
    "\n",
    "        for card in cards:\n",
    "            count += 1\n",
    "\n",
    "            record = extract_data(card)\n",
    "            print(\"Retrieved record\", count)\n",
    "            print(record)\n",
    "            records.append(record)\n",
    "        \n",
    "        try:\n",
    "            url = BASE_URL + soup.find('a', {'aria-label' : 'Next Page'}).get('href')\n",
    "            url = get_scrapeops_url(url)\n",
    "        except AttributeError:\n",
    "            break\n",
    "\n",
    "        if count % 30 == 0:\n",
    "            print(\"Pausing...\")\n",
    "            time.sleep(2)\n",
    "\n",
    "    # save to csv file\n",
    "    with open('./data/job_data.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['job_title', 'job_url', 'company', 'company_location','salary', 'time_commitment', 'job_description', 'post_date', 'today']\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(fieldnames)\n",
    "        writer.writerows(records)\n",
    "\n",
    "    \n",
    "\n",
    "main('data analyst', 'lagos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
